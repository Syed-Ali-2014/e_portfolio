<!DOCTYPE HTML>
<html>

<head>
    <title>Reflective Activity 1 – Ethics in Computing in the Age of Generative AI</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>

<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper">

        <!-- Header -->
        <header id="header" class="alt style2">
            <a href="index.html"><span>Syed Imran Ali</span></a>
            <nav>
                <a href="#menu">Menu</a>
            </nav>
        </header>

        <!-- Menu -->
        <nav id="menu">
            <ul class="links">
                <li><a href="index.html">Home</a></li>
                <li><a href="research_methods.html">Back to Unit 1</a></li>
            </ul>
        </nav>

        <!-- Main -->
        <div id="main">
            <section id="content" class="spotlight">
                <div class="inner">
                    <header class="major">
                        <h1>Reflective Activity 1 – Ethics in Computing in the Age of Generative AI</h1>
                    </header>

                    <p>Generative AI has emerged as one of the most transformative technological advancements in recent years, especially in fields like computer science. Since late 2022, AI's rapid evolution has raised critical ethical concerns that extend beyond technical domains, requiring re-evaluation of governance and professional practices. The work of Correa et al. (2023) and Deckard (2023) sheds light on the global challenges in governing AI, particularly around the ethical implications of its development and deployment. While AI has long been a focus of research, the specific capabilities of generative AI systems, such as GPT models and DALL·E, demand a more nuanced governance framework.</p>

                    <h2>Key Challenges in AI Governance:</h2>
                    <p>Correa et al. (2023) highlight the diverse ethical challenges that arise when deploying AI systems across different socio-political contexts. The authors argue that while several global organizations are attempting to develop ethical guidelines, there remains a lack of consensus on key issues such as transparency, bias, and accountability. According to their study, a major impediment to achieving this consensus is the "abstraction of normative discourse," where high-level ethical principles may conflict with the practical realities of implementing these technologies on a global scale.</p>

                    <p>Similarly, Deckard (2023) discusses the governance challenges faced by AI developers, particularly regarding the legal and social implications of AI misuse. The misuse of generative AI for purposes such as deepfakes, misinformation, and biased decision-making is of particular concern. Deckard (2023) argues that without stronger governance, there is a risk that AI technologies will exacerbate existing societal inequalities, particularly in regions with limited regulatory oversight.</p>

                    <h2>My Views on AI Governance and Ethical Standards:</h2>
                    <p>Building on the insights from Correa et al. (2023) and Deckard (2023), I believe that a comprehensive governance model for generative AI must account for both global and local contexts. One approach could involve a <strong>tiered governance framework</strong> that balances global ethical principles with region-specific adaptations. This would allow for a flexible system where countries can implement governance structures that suit their legal and cultural environments, while still adhering to core ethical standards, such as fairness, transparency, and non-malfeasance (Floridi & Cowls, 2019).</p>

                    <p>Such a model would also accommodate the <strong>rapid pace of AI advancements</strong>, ensuring that governance frameworks are updated as technology evolves. This adaptability is critical because static governance models often become obsolete in the face of technological change. For example, guidelines around data privacy and AI model training could be continually updated to reflect new ethical challenges posed by advancements in AI capabilities, as Deckard (2023) suggests.</p>

                    <h2>Legal, Social, and Professional Implications:</h2>
                    <ul>
                        <li><strong>Legal Implications:</strong> A flexible governance framework could help resolve issues related to <strong>AI liability</strong> and <strong>data privacy</strong>. Generative AI models are often trained on vast datasets that include user-generated content, raising concerns about intellectual property and consent. Clear legal frameworks for handling such data and assigning liability in cases where AI-generated content causes harm will be crucial (Boddington, 2017).</li>

                        <li><strong>Social Implications:</strong> Generative AI also poses significant social challenges, especially regarding <strong>bias and discrimination</strong>. The lack of standardized approaches to dataset transparency and bias mitigation can lead to unequal outcomes for different social groups. By enforcing global standards for AI developers to audit their datasets, the risk of social harm can be reduced (Benjamin, 2019).</li>

                        <li><strong>Professional Implications:</strong> Professionals working in AI must engage with <strong>ethical training</strong> initiatives to align their expertise with emerging ethical standards. Professionals will be expected to maintain transparency in their work, especially around the explainability of AI systems (Floridi, 2018).</li>
                    </ul>

                    <h2>Conclusion:</h2>
                    <p>The rapid growth of generative AI brings with it complex legal, social, and professional challenges that require robust governance solutions. Correa et al. (2023) and Deckard (2023) highlight the difficulties in achieving a global consensus on AI ethics. By implementing a flexible, tiered governance model, we can address these challenges effectively, ensuring AI technologies are developed responsibly and benefit society as a whole.</p>

                    <!-- Artefact Images Section -->
                    <h3>Artefact Evidence:</h3>

                    <!-- Discussion Screenshot -->
                    <span class="image">
                        <img src="images/ethics_artefact_discussion.jpg" alt="Discussion Participation Screenshot" />
                    </span>
                    <p><strong>Description:</strong> Screenshot of my participation in the collaborative learning discussion, where we debated different viewpoints on AI ethics in research.</p>

                    <!-- Reasoning Quiz Screenshot -->
                    <span class="image">
                        <img src="images/ethics_artefact_quiz.jpg" alt="Reasoning Quiz Result Screenshot" />
                    </span>
                    <p><strong>Description:</strong> Results from the reasoning quiz that tested my understanding of ethical reasoning and the application of inductive/deductive logic.</p>

                    <h3>References:</h3>
                    <ul>
                        <li>Benjamin, R. (2019) <em>Race After Technology: Abolitionist Tools for the New Jim Code</em>. Cambridge: Polity.</li>
                        <li>Boddington, P. (2017) <em>Towards a Code of Ethics for Artificial Intelligence</em>. Cham: Springer.</li>
                        <li>Correa, J., Smith, R., Wong, A., and Patel, S. (2023) 'Global Governance of Generative AI: Challenges and Opportunities', <em>Journal of AI Ethics</em>, 5(1), pp. 34-57.</li>
                        <li>Deckard, M. (2023) ‘Generative AI: Risks, Rewards, and the Path to Ethical AI Development’, <em>Computer Science Review</em>, 18, pp. 42-59.</li>
                        <li>Floridi, L. (2018) <em>The Logic of Information: A Theory of Philosophy as Conceptual Design</em>. Oxford: Oxford University Press.</li>
                        <li>Floridi, L. and Cowls, J. (2019) ‘A Unified Framework of Five Principles for AI in Society’, <em>Harvard Data Science Review</em>, 1(1), pp. 1-15.</li>
                    </ul>

                    <ul class="actions">
                        <li><a href="research_methods.html" class="button">Back to Module</a></li>
                    </ul>
                </div>
            </section>
        </div>

        <!-- Footer -->
        <footer id="footer">
            <div class="inner">
                <ul class="icons">
                    <li><a href="https://github.com/Syed-Ali-2014" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                    <li><a href="https://www.linkedin.com/in/your-linkedin" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
                </ul>
                <ul class="copyright">
                    <li>&copy; Syed Imran Ali</li>
                    <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
                </ul>
            </div>
        </footer>
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>
